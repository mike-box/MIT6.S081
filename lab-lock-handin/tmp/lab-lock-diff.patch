diff --git a/kernel/bio.c b/kernel/bio.c
index 60d91a6..8369fcc 100644
--- a/kernel/bio.c
+++ b/kernel/bio.c
@@ -23,33 +23,48 @@
 #include "fs.h"
 #include "buf.h"
 
+#define MAX_HASH_BUCKETS 13
+#define NULL 0
+extern uint ticks;
+
 struct {
+  struct buf buf[NBUF]; 
   struct spinlock lock;
-  struct buf buf[NBUF];
-
+  // hash table 
+  struct spinlock hashlock[MAX_HASH_BUCKETS];
+  struct buf hashtable[MAX_HASH_BUCKETS];
   // Linked list of all buffers, through prev/next.
   // Sorted by how recently the buffer was used.
   // head.next is most recent, head.prev is least.
-  struct buf head;
 } bcache;
 
+static int bhash(int blockno);
+static int btime();
+
 void
 binit(void)
 {
-  struct buf *b;
-
-  initlock(&bcache.lock, "bcache");
-
-  // Create linked list of buffers
-  bcache.head.prev = &bcache.head;
-  bcache.head.next = &bcache.head;
-  for(b = bcache.buf; b < bcache.buf+NBUF; b++){
-    b->next = bcache.head.next;
-    b->prev = &bcache.head;
-    initsleeplock(&b->lock, "buffer");
-    bcache.head.next->prev = b;
-    bcache.head.next = b;
-  }
+	struct buf *b;
+	// init buffer lock and init free list buffer
+	// initial the hash table and hash lock
+	for (int i = 0; i < MAX_HASH_BUCKETS; ++i) {
+		initlock(&bcache.hashlock[i], "hashlock");
+		// Create linked list of buffers
+		bcache.hashtable[i].prev = &bcache.hashtable[i];
+		bcache.hashtable[i].next = &bcache.hashtable[i];
+	}
+	initlock(&bcache.lock, "bcache");
+	for(b = bcache.buf; b < bcache.buf + NBUF; b++){
+		initsleeplock(&b->lock, "bufferlock");
+		b->timestamp = 0;
+		b->dev = -1;
+		b->blockno = -1;
+		b->refcnt = 0;
+		b->next = bcache.hashtable[0].next;
+		b->prev = &bcache.hashtable[0];
+		bcache.hashtable[0].next->prev = b;
+		bcache.hashtable[0].next = b;
+	}
 }
 
 // Look through buffer cache for block on device dev.
@@ -59,32 +74,83 @@ static struct buf*
 bget(uint dev, uint blockno)
 {
   struct buf *b;
-
-  acquire(&bcache.lock);
-
+  struct buf * lrub = 0;
+  int minticks = -1;
+  int no = bhash(blockno);
+  
+  acquire(&bcache.hashlock[no]);
   // Is the block already cached?
-  for(b = bcache.head.next; b != &bcache.head; b = b->next){
-    if(b->dev == dev && b->blockno == blockno){
+  for(b = bcache.hashtable[no].next; b != &bcache.hashtable[no]; b = b->next){
+	if(b->dev == dev && b->blockno == blockno){
       b->refcnt++;
-      release(&bcache.lock);
+      release(&bcache.hashlock[no]);
       acquiresleep(&b->lock);
       return b;
     }
   }
+  release(&bcache.hashlock[no]);
 
   // Not cached.
   // Recycle the least recently used (LRU) unused buffer.
-  for(b = bcache.head.prev; b != &bcache.head; b = b->prev){
-    if(b->refcnt == 0) {
-      b->dev = dev;
-      b->blockno = blockno;
-      b->valid = 0;
-      b->refcnt = 1;
-      release(&bcache.lock);
+  acquire(&bcache.lock);
+  acquire(&bcache.hashlock[no]);
+  for(b = bcache.hashtable[no].next; b != &bcache.hashtable[no]; b = b->next){
+	if(b->dev == dev && b->blockno == blockno){
+      b->refcnt++;
+      release(&bcache.hashlock[no]);
+	  release(&bcache.lock);
       acquiresleep(&b->lock);
       return b;
     }
+	if(b->refcnt == 0 && minticks >= b->timestamp) {
+		lrub = b;
+		minticks = b->timestamp;
+	}
+  }
+  if (lrub) {
+  	lrub->dev = dev;
+	lrub->blockno = blockno;
+    lrub->valid = 0;
+	lrub->refcnt = 1;
+	release(&bcache.hashlock[no]);
+	release(&bcache.lock);
+    acquiresleep(&lrub->lock);
+	return lrub;
   }
+
+  // we steal a buffer block from other buckets
+  for (int i = 1; i < MAX_HASH_BUCKETS; ++i) {
+	int newno = bhash(no + i);
+	acquire(&bcache.hashlock[newno]);
+  	for (b = bcache.hashtable[newno].prev; b != &bcache.hashtable[newno]; b = b->prev){
+		if(b->refcnt == 0 && minticks >= b->timestamp) {
+			lrub = b;
+			minticks = b->timestamp;
+		}
+	}
+	if (lrub) {
+	  	lrub->dev = dev;
+		lrub->blockno = blockno;
+	    lrub->valid = 0;
+		lrub->refcnt = 1;
+		lrub->next->prev = lrub->prev;
+		lrub->prev->next = lrub->next;
+		lrub->next = bcache.hashtable[no].next;
+		lrub->prev = &bcache.hashtable[no];
+		bcache.hashtable[no].next->prev = lrub;
+    	bcache.hashtable[no].next = lrub;
+		release(&bcache.hashlock[newno]);
+		release(&bcache.hashlock[no]);
+		release(&bcache.lock);
+	    acquiresleep(&lrub->lock);
+		return lrub;
+	}
+  	release(&bcache.hashlock[newno]);
+  }
+  release(&bcache.hashlock[no]);
+  release(&bcache.lock);
+  
+  // we check the the cache again and the one block must atomic  
   panic("bget: no buffers");
 }
 
@@ -118,36 +184,54 @@ brelse(struct buf *b)
 {
   if(!holdingsleep(&b->lock))
     panic("brelse");
-
+  
   releasesleep(&b->lock);
-
-  acquire(&bcache.lock);
+  int no = bhash(b->blockno);
+  acquire(&bcache.hashlock[no]);
   b->refcnt--;
   if (b->refcnt == 0) {
-    // no one is waiting for it.
-    b->next->prev = b->prev;
-    b->prev->next = b->next;
-    b->next = bcache.head.next;
-    b->prev = &bcache.head;
-    bcache.head.next->prev = b;
-    bcache.head.next = b;
-  }
-  
-  release(&bcache.lock);
+ 	b->timestamp = btime();
+  } 	
+  release(&bcache.hashlock[no]);
+  // bdegub();
 }
 
 void
 bpin(struct buf *b) {
-  acquire(&bcache.lock);
+  int no = bhash(b->blockno);
+  acquire(&bcache.hashlock[no]);
   b->refcnt++;
-  release(&bcache.lock);
+  release(&bcache.hashlock[no]);
 }
 
 void
 bunpin(struct buf *b) {
-  acquire(&bcache.lock);
+  int no = bhash(b->blockno);
+  acquire(&bcache.hashlock[no]);
   b->refcnt--;
-  release(&bcache.lock);
+  release(&bcache.hashlock[no]);
+}
+
+static int bhash(int blockno) {
+  return blockno%MAX_HASH_BUCKETS;
 }
 
+static int btime(){
+  return ticks;
+}
+
+#if 0
+static void bdegub(){
+  for (int i = 0; i < MAX_HASH_BUCKETS; ++i) {
+  	struct buf *b;
+	acquire(&bcache.hashlock[i]);
+    printf("block : %d================\n",i);
+	for (b = bcache.hashtable[i].next; b != &bcache.hashtable[i]; b = b->next) {
+		printf("%p %p %p\n",b->prev,b,b->next);
+		printf("dev:%d block:%d refcnt:%d timestamp:%d\n",b->dev,b->blockno,b->refcnt,b->timestamp);
+	}
+	release(&bcache.hashlock[i]);
+  }
+}
+#endif
 
diff --git a/kernel/buf.h b/kernel/buf.h
index 4616e9e..813ac1e 100644
--- a/kernel/buf.h
+++ b/kernel/buf.h
@@ -5,6 +5,7 @@ struct buf {
   uint blockno;
   struct sleeplock lock;
   uint refcnt;
+  uint timestamp;
   struct buf *prev; // LRU cache list
   struct buf *next;
   uchar data[BSIZE];
diff --git a/kernel/kalloc.c b/kernel/kalloc.c
index fa6a0ac..1b9d1a5 100644
--- a/kernel/kalloc.c
+++ b/kernel/kalloc.c
@@ -21,12 +21,19 @@ struct run {
 struct {
   struct spinlock lock;
   struct run *freelist;
-} kmem;
+  int  freesize;
+  char name[16];
+} kmem[NCPU];
 
 void
 kinit()
-{
-  initlock(&kmem.lock, "kmem");
+{	
+  for (int i = 0; i < NCPU; ++i) {
+  	snprintf(kmem[i].name, 16, "%s%d", "kmem", i);
+	initlock(&kmem[i].lock, kmem[i].name);
+	kmem[i].freelist = 0;
+	kmem[i].freesize = 0;
+  } // we wiil alloc each cup heap lock and list
   freerange(end, (void*)PHYSTOP);
 }
 
@@ -53,13 +60,17 @@ kfree(void *pa)
 
   // Fill with junk to catch dangling refs.
   memset(pa, 1, PGSIZE);
-
   r = (struct run*)pa;
 
-  acquire(&kmem.lock);
-  r->next = kmem.freelist;
-  kmem.freelist = r;
-  release(&kmem.lock);
+  //add this block to the free list
+  push_off();
+  int hart = cpuid();
+  pop_off();
+  
+  acquire(&kmem[hart].lock);
+  r->next = kmem[hart].freelist;
+  kmem[hart].freelist = r;
+  release(&kmem[hart].lock);
 }
 
 // Allocate one 4096-byte page of physical memory.
@@ -70,11 +81,29 @@ kalloc(void)
 {
   struct run *r;
 
-  acquire(&kmem.lock);
-  r = kmem.freelist;
-  if(r)
-    kmem.freelist = r->next;
-  release(&kmem.lock);
+  //add this block to the free list
+  push_off();
+  int hart = cpuid();
+  pop_off();
+  
+  acquire(&kmem[hart].lock);
+  r = kmem[hart].freelist;
+  if(r) {
+  	kmem[hart].freelist = r->next;
+  }
+  release(&kmem[hart].lock);
+  if(r == 0) {
+	// we steal memory from other cpus
+	for (int i = 0; i < NCPU; ++i) {
+		acquire(&kmem[i].lock);
+		r = kmem[i].freelist;
+		if(r) {
+			kmem[i].freelist = r->next;
+		}
+		release(&kmem[i].lock);
+		if(r) break;
+	}
+  }
 
   if(r)
     memset((char*)r, 5, PGSIZE); // fill with junk
diff --git a/kernel/proc.c b/kernel/proc.c
index ebbf5a2..aaa9121 100644
--- a/kernel/proc.c
+++ b/kernel/proc.c
@@ -649,7 +649,7 @@ either_copyout(int user_dst, uint64 dst, void *src, uint64 len)
     memmove((char *)dst, src, len);
     return 0;
   }
-}
+}                  
 
 // Copy from either a user address, or kernel address,
 // depending on usr_src.
diff --git a/kernel/trap.c b/kernel/trap.c
index a63249e..62c5976 100644
--- a/kernel/trap.c
+++ b/kernel/trap.c
@@ -218,3 +218,4 @@ devintr()
   }
 }
 
+
diff --git a/time.txt b/time.txt
new file mode 100644
index 0000000..bc06962
--- /dev/null
+++ b/time.txt
@@ -0,0 +1 @@
+10101010101010101010
